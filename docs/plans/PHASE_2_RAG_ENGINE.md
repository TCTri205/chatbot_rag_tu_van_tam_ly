# üß† Phase 2 Detailed Plan: RAG Engine & Core Logic

**Status**: ‚úÖ **COMPLETED** (December 15, 2024)

**M·ª•c ti√™u**: X√¢y d·ª±ng "B·ªô n√£o" cho chatbot. Sau giai ƒëo·∫°n n√†y, bot c√≥ th·ªÉ hi·ªÉu c√¢u h·ªèi, t√¨m ki·∫øm ki·∫øn th·ª©c trong PDF v√† tr·∫£ l·ªùi th·∫•u c·∫£m.

**Achievements**:

- ‚úÖ ChromaDB integration v·ªõi v2 API
- ‚úÖ RAG pipeline v·ªõi source citations
- ‚úÖ Session management (Redis + PostgreSQL)
- ‚úÖ Crisis detection system
- ‚úÖ Guest conversation support
- ‚úÖ Database timing optimization (pg_isready)
- ‚úÖ System settings seeding via migration

---

## 1. RAG Core Services

### Step 1.1: ChromaDB Setup

*M·ª•c ƒë√≠ch*: N∆°i l∆∞u tr·ªØ vector ki·∫øn th·ª©c.

1. **C·∫≠p nh·∫≠t `docker-compose.yml`** (N·∫øu ch∆∞a):
    - Image: `chromadb/chroma:0.5.5` (0.5.4+ fixes NumPy 2.0 compatibility, backward compatible with 0.4.22 client).
    - Volume: `./chroma_data:/chroma/chroma`.
    - Port: `8000` (Map ra 8001 ƒë·ªÉ tr√°nh ƒë·ª•ng backend).

2. **`src/core/vector_store.py`** (Code Snippet):

    ```python
    import chromadb
    from src.config import settings

    def get_chroma_client():
        # K·∫øt n·ªëi t·ªõi Chroma container qua Docker Network
        return chromadb.HttpClient(
            host=settings.CHROMA_HOST,  # "chroma"
            port=settings.CHROMA_PORT   # 8000
        )

    def get_collection():
        client = get_chroma_client()
        return client.get_or_create_collection("psychology_knowledge")
    ```

### Step 1.2: RAG Pipeline Implementation

*File*: `src/services/rag_service.py`

1. **Ch·ª©c nƒÉng Chunking & Embedding**:
    - S·ª≠ d·ª•ng `RecursiveCharacterTextSplitter` (chunk_size=1000, overlap=200).
    - S·ª≠ d·ª•ng `google-generativeai` ƒë·ªÉ embedding (`text-embedding-004`).

2. **Ch·ª©c nƒÉng Hybrid Search** (Key feature):
    - Query ChromaDB l·∫•y Top-10 semantic results.
    - S·ª≠ d·ª•ng `rank_bm25` (in-memory) ho·∫∑c Chroma metadata filtering ƒë·ªÉ tƒÉng ƒë·ªô ch√≠nh x√°c t·ª´ kh√≥a.

3. **Ch·ª©c nƒÉng Reranking**:
    - S·ª≠ d·ª•ng `CrossEncoder` (nh·∫π) ho·∫∑c g·ªçi l·∫°i Gemini Flash ch·∫•m ƒëi·ªÉm Top-10 -> L·∫•y Top-3.

### Step 1.3: Ingestion Script

*File*: `src/scripts/ingest.py`

### Step 1.3: Ingestion Script (Snippet)

*File*: `src/scripts/ingest.py`

```python
import os
from pypdf import PdfReader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from src.core.vector_store import get_collection
from src.config import settings
import google.generativeai as genai

# Configure Gemini
genai.configure(api_key=settings.GOOGLE_API_KEY)

def ingest_docs():
    collection = get_collection()
    data_dir = "./data"
    
    for filename in os.listdir(data_dir):
        if not filename.endswith(".pdf"): continue
        
        # 1. Read PDF
        print(f"Processing {filename}...")
        reader = PdfReader(os.path.join(data_dir, filename))
        text = ""
        for page in reader.pages:
            text += page.extract_text() + "\n"
            
        # 2. Chunking
        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        chunks = splitter.split_text(text)
        
        # 3. Embedding & Upsert
        # Note: Th·ª±c t·∫ø n√™n batching ƒë·ªÉ ti·∫øt ki·ªám API
        ids = [f"{filename}_{i}" for i in range(len(chunks))]
        metadatas = [{"source": filename, "page": 0} for _ in chunks]
        
        # G·ªçi Gemini Embeddings (gi·∫£ l·∫≠p function wrapper)
        embeddings = [
            genai.embed_content(
                model="models/text-embedding-004",
                content=chunk,
                task_type="retrieval_document"
            )['embedding'] 
            for chunk in chunks
        ]
        
        collection.upsert(
            ids=ids,
            documents=chunks,
            embeddings=embeddings,
            metadatas=metadatas
        )
        print(f"Upserted {len(chunks)} chunks.")

if __name__ == "__main__":
    ingest_docs()
```

1. **Ch·∫°y th·ª≠**:

    ```bash
    docker-compose exec backend python -m src.scripts.ingest
    ```

---

## 2. API Implementation (Business Logic)

### Step 2.1: Chat API

*File*: `src/api/v1/chat.py`

1. **Endpoint**: `POST /chat`.
2. **Tasks**:
    - Verify Session ID (from Redis).
    - **Safety Check**: Regex keyword "t·ª± t·ª≠", "ch·∫øt", "t·ª± h·∫°i". N·∫øu c√≥ -> Tr·∫£ v·ªÅ Crisis Response (403).
    - **Context Retrieval**: G·ªçi RAG Service l·∫•y Top-3 chunks.
    - **Generate**: G·ªçi Gemini API v·ªõi System Prompt + Context.
    - **Save DB**: L∆∞u User Message & Bot Response v√†o DB (async).

3. **System Prompt M·∫´u** (Quan tr·ªçng!):

    ```text
    B·∫°n l√† m·ªôt chuy√™n gia t∆∞ v·∫•n t√¢m l√Ω AI nh√¢n √°i, th·∫•u c·∫£m v√† chuy√™n nghi·ªáp.
    Nhi·ªám v·ª•: S·ª≠ d·ª•ng th√¥ng tin trong [CONTEXT] ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng.

    Quy t·∫Øc b·∫Øt bu·ªôc:
    1. Lu√¥n l·∫Øng nghe v√† x√°c nh·∫≠n c·∫£m x√∫c tr∆∞·ªõc khi ƒë∆∞a l·ªùi khuy√™n.
    2. Ch·ªâ tr·∫£ l·ªùi d·ª±a tr√™n ki·∫øn th·ª©c t√¢m l√Ω h·ªçc v√† context ƒë∆∞·ª£c cung c·∫•p.
    3. KH√îNG ph√°n x√©t, ƒë·ªï l·ªói ho·∫∑c b·ªãa ƒë·∫∑t th√¥ng tin.
    4. Tr√≠ch d·∫´n ngu·ªìn n·∫øu c√≥ (VD: "Theo s√°ch X, trang Y...").
    5. Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát t·ª± nhi√™n, ·∫•m √°p.
    ```

### Step 2.2: Mood API

*File*: `src/api/v1/mood.py`

1. **Endpoint**: `POST /moods`.
    - Insert v√†o b·∫£ng `mood_entries`.
2. **Endpoint**: `GET /moods/history`.
    - Query Aggregate: `SELECT AVG(mood_value), DATE(created_at) GROUP BY DATE(created_at)`.

---

## ‚úÖ Verification Checklist (Phase 2)

**Automated Scripts** (Recommended):

1. **Quick Start**:

   ```bash
   scripts\phase2\quick_start_phase2.bat
   ```

   X√¢y d·ª±ng, kh·ªüi ƒë·ªông, v√† verify to√†n b·ªô h·ªá th·ªëng.

2. **Verification**:

   ```bash
   scripts\phase2\verify_phase2.bat
   ```

   Ki·ªÉm tra: Docker containers, Database health, ChromaDB, System Settings.

3. **API Testing**:

   ```bash
   scripts\phase2\test_phase2_apis.bat
   ```

   Test: Session init, Crisis detection, Normal chat, Chat history.

**Manual Tests** (Optional):

1. **Test ChromaDB v2 API**:

    ```bash
    curl http://localhost:8001/api/v2/heartbeat
    # Expected: Timestamp (e.g., 1734234567890123456)
    ```

2. **Test Session Init**:

    ```bash
    curl -X POST http://localhost:8080/api/v1/sessions/init \
      -H "Content-Type: application/json" \
      -d '{}'
    # Expected: {session_id, conversation_id, greeting, created_at}
    ```

3. **Test Crisis Detection**:

    ```bash
    curl -X POST http://localhost:8080/api/v1/chat \
      -H "Content-Type: application/json" \
      -H "X-Session-ID: <your_session_id>" \
      -d '{"content": "t√¥i mu·ªën ch·∫øt"}'
    # Expected: {is_crisis: true, message: ..., hotlines: [...]}
    ```

4. **Test RAG Chat**:

    ```bash
    curl -X POST http://localhost:8080/api/v1/chat \
      -H "Content-Type: application/json" \
      -H "X-Session-ID: <your_session_id>" \
      -d '{"content": "l√†m sao ƒë·ªÉ b·ªõt lo √¢u?"}'
    # Expected: {message_id, role: "assistant", content: ..., sources: [], is_crisis: false}
    ```

5. **Verify Database**:

    ```bash
    # Check system_settings seeded
    docker-compose exec db psql -U chatbot_user -d chatbot_db -c "SELECT key FROM system_settings;"
    
    # Check guest conversation (user_id nullable)
    docker-compose exec db psql -U chatbot_user -d chatbot_db -c "SELECT id, user_id FROM conversations LIMIT 5;"
    ```

üëâ **Phase 2 COMPLETED khi t·∫•t c·∫£ tests tr√™n PASS.**
